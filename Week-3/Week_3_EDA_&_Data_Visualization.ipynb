{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dkGJBolLYSDa",
      "metadata": {
        "id": "dkGJBolLYSDa"
      },
      "source": [
        "## Exploratory Data Analysis\n",
        "\n",
        "\n",
        "*Rohan Chopra*\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a84091cd",
      "metadata": {},
      "source": [
        "Attribution: Parts of this notebook are adapted from Fraida Fund's 'Intro to ML' material. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hT5TQGelYSDb",
      "metadata": {
        "id": "hT5TQGelYSDb"
      },
      "source": [
        "In this notebook\n",
        "----------------\n",
        "-   We learn a basic ‚Äúrecipe‚Äù for exploratory data analysis and apply it\n",
        "    to an example.\n",
        "-   Use Pandas, Matplotlib, and Seaborn to create simple plots.\n",
        "\n",
        "We'll cover plotting line plots, scatter plots, bar plots, and histograms, and how to manipulate the style of your plots with Matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "895a9603",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "HvQZ8EnSYSDc",
      "metadata": {
        "id": "HvQZ8EnSYSDc"
      },
      "source": [
        "Introduction\n",
        "------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yCveVDB7YSDd",
      "metadata": {
        "id": "yCveVDB7YSDd"
      },
      "source": [
        "### What makes data ‚Äúgood‚Äù?\n",
        "\n",
        "What makes a good data set?\n",
        "\n",
        "-   **Quantity/Size**: the more *samples* are in the data set, the more examples\n",
        "    your machine learning model will be able to learn from, and the\n",
        "    better it will do. Often, a simple machine learning model trained on\n",
        "    a large data set will outperform a ‚Äúfancy‚Äù model on a small data\n",
        "    set.\n",
        "-   **Quality**: Are there *predictive* features in the data? Are no\n",
        "    values (or very few values) missing, noisy, or incorrect? Is the\n",
        "    scenario in which the data collected similar to the scenario in\n",
        "    which your model will be used? These are examples of questions that\n",
        "    we might ask to evaluate the quality of a data set."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bnheDBSYSDe",
      "metadata": {
        "id": "0bnheDBSYSDe"
      },
      "source": [
        "One of the most important principles in machine learning is: **garbage\n",
        "in, garbage out**. If the data you use to train a machine learning model\n",
        "is problematic, or not well suited for the purpose, then even the best\n",
        "model will produce useless predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zKwzxYV9YSDe",
      "metadata": {
        "id": "zKwzxYV9YSDe"
      },
      "source": [
        "\n",
        "### üîéExploratory data analysis (EDA) serves several important purposes:\n",
        "\n",
        "-    *Detect and Correct Mistakes*: EDA helps us identify errors or inconsistencies in the data, such as missing values or outliers. By spotting these mistakes early on, we can take steps to correct them and ensure the data is reliable.\n",
        "\n",
        "-    *Check Assumptions*: EDA allows us to validate our assumptions about the data. We can examine the distributions of variables and test whether they meet our expectations. If our assumptions are incorrect, it may influence our modeling approach.\n",
        "\n",
        "-    *Identify Relationships Between Features*: EDA helps us uncover potential relationships or patterns between different features in the dataset. This can provide valuable insights into the underlying structure of the data and inform feature engineering decisions.\n",
        "\n",
        "-    *Assess Relationships with Target Variable*: EDA enables us to explore the relationship between features and the target variable. Understanding the direction and magnitude of these relationships helps us assess the predictive power of the features and select the most relevant ones for our machine learning task."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hmIvRJ3ZYSDf",
      "metadata": {
        "id": "hmIvRJ3ZYSDf"
      },
      "source": [
        "üñä ‚ÄúRecipe‚Äù for exploratory data analysis\n",
        "--------------------------------------\n",
        "\n",
        "We will practice using a basic ‚Äúrecipe‚Äù for exploratory data analysis.:\n",
        "\n",
        "1.  *Define Expectations*: Clearly state your expectations and objectives for the EDA\n",
        "process. Understand what you hope to achieve and what insights you're seeking from the data.\n",
        "\n",
        "2.  *Load Data*: Begin by loading the dataset into your analysis environment, ensuring that it is loaded correctly and all necessary columns and rows are included.\n",
        "\n",
        "3.  *Sanity Checks*: Perform sanity checks to ensure that the data aligns with your expectations. Check for data consistency, missing values, and any anomalies that may require cleaning or filtering.\n",
        "\n",
        "4. *Clean and Preprocess*: Clean and preprocess the data as needed to address any issues identified during the sanity checks. This may involve handling missing values, removing outliers, or standardizing data formats.\n",
        "\n",
        "5. *Explore Relationships*: Explore relationships within the data to identify potential features and target variables for further analysis. Use visualizations and statistical techniques to uncover patterns, correlations, and trends."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LDpIegE_YSDf",
      "metadata": {
        "id": "LDpIegE_YSDf"
      },
      "source": [
        "Example: Brooklyn Bridge Pedestrian Dataset\n",
        "--------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50RU3YH_YSDf",
      "metadata": {
        "id": "50RU3YH_YSDf"
      },
      "source": [
        "The Brooklyn Bridge is a bridge that connects Brooklyn and Manhattan. It\n",
        "supports vehicles, pedestrians, and bikers.\n",
        "\n",
        "![](https://brooklyneagle.com/wp-content/uploads/2019/01/7-Brooklyn-Bridge-pedestrians-in-bike-lane-to-right-of-white-stripe-January-2019-photo-by-Lore-Croghan-600x397.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gV8-pAS_YSDg",
      "metadata": {
        "id": "gV8-pAS_YSDg"
      },
      "source": [
        "Suppose you are developing a machine learning model to predict the\n",
        "volume of pedestrian traffic on the Brooklyn Bridge. There is a dataset\n",
        "available that you think may be useful as training data: [Brooklyn\n",
        "Bridge Automated Pedestrian Counts\n",
        "dataset](https://data.cityofnewyork.us/Transportation/Brooklyn-Bridge-Automated-Pedestrian-Counts-Demons/6fi9-q3ta),\n",
        "from the NYC Department of Transportation.\n",
        "\n",
        "We will practice applying the ‚Äúrecipe‚Äù for exploratory data analysis to\n",
        "this data.\n",
        "\n",
        "We will use the `pandas` library in Python, which includes many powerful\n",
        "utilities for managing data. You can refer to the [`pandas`\n",
        "reference](https://pandas.pydata.org/pandas-docs/stable/reference/index.html)\n",
        "for more details on the `pandas` functions used in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N0ZiiVk0YSDg",
      "metadata": {
        "id": "N0ZiiVk0YSDg"
      },
      "source": [
        "### Set down *expectations* about the data\n",
        "\n",
        "The first step is to codify your expectations about the data *before*\n",
        "you look at it:\n",
        "\n",
        "-   Read about *methodology* and *data codebook*\n",
        "-   How many rows and columns are in the data?\n",
        "-   What does each variable mean? What units are data recorded in? What\n",
        "    is the expected range or typical value for each column?\n",
        "-   What variables do you think could be used as target variable? What\n",
        "    variables could be used as features from which to learn?\n",
        "-   How was data collected? Identify sampling issues, timeliness issues,\n",
        "    fairness issues, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TDJPzRFYYSDg",
      "metadata": {
        "id": "TDJPzRFYYSDg"
      },
      "source": [
        "For the Brooklyn Bridge dataset, you can review the associated\n",
        "documentation on the NYC Data website:\n",
        "\n",
        "-   [NYC Data\n",
        "    Website](https://data.cityofnewyork.us/Transportation/Brooklyn-Bridge-Automated-Pedestrian-Counts-Demons/6fi9-q3ta)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "THswJZBlYSDg",
      "metadata": {
        "id": "THswJZBlYSDg"
      },
      "source": [
        "### Load data and check that it is loaded correctly\n",
        "\n",
        "The next step is to load the data in preparation for our exploratory\n",
        "data analysis. Then, we‚Äôll check that it is loaded correctly.\n",
        "\n",
        "Some examples of the things we‚Äôll look for include:\n",
        "\n",
        "-   Does the `DataFrame` have the correct number of rows and columns?\n",
        "-   Is the first row of ‚Äúdata‚Äù in the `DataFrame` real data, or is it\n",
        "    column labels that were misinterpreted as data? (Similarly, are the\n",
        "    column labels actually labels, or are they the first row of data?)\n",
        "\n",
        "At this stage, we might also do some very basic manipulation of the data\n",
        "- for example, compute some fields that are derived directly from other\n",
        "fields. (For example, suppose you have a ‚Äúdistance‚Äù field in miles and\n",
        "you wanted to convert it to meters - you could do that here!)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12fmsyq_YSDg",
      "metadata": {
        "id": "12fmsyq_YSDg"
      },
      "source": [
        "First, we will import some useful libraries:\n",
        "\n",
        "-   In Python - libraries add powerful functionality\n",
        "-   You can import an entire library (`import foo`) or part\n",
        "    (`from foo import bar`)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "I7nJV7bcYSDh",
      "metadata": {
        "id": "I7nJV7bcYSDh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# set up notebook to show all outputs in a cell, not only last one\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sztFoDG0YSDh",
      "metadata": {
        "id": "sztFoDG0YSDh"
      },
      "source": [
        "Now we are ready to read in our data!\n",
        "\n",
        "‚ùì: What are the 2 main types of data that Pandas supports?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "vr_N5EByYSDi",
      "metadata": {
        "id": "vr_N5EByYSDi"
      },
      "outputs": [],
      "source": [
        "url = 'https://data.cityofnewyork.us/api/views/6fi9-q3ta/rows.csv?accessType=DOWNLOAD'\n",
        "df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZsNJwg8BYSDi",
      "metadata": {
        "id": "ZsNJwg8BYSDi"
      },
      "source": [
        "We will want to verify that the data was loaded correctly. For *tabular*\n",
        "data, we can start by looking at the first few rows of data or the last\n",
        "few rows of data with the `head` and `tail` functions, respectively.\n",
        "(For data that is not tabular, such as image, text, or audio data, we\n",
        "would similarly start by looking at some samples.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I8shVEn_YSDi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "I8shVEn_YSDi",
        "outputId": "bccab3b9-49a0-4b44-9aad-5b425d23dbc4"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HMQYM0-2YSDi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HMQYM0-2YSDi",
        "outputId": "e3d10f82-4170-40e0-f204-e0914f67b347"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mOorNmXAYSDi",
      "metadata": {
        "id": "mOorNmXAYSDi"
      },
      "source": [
        "We can also get a few random rows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uQ9Vt1rpYSDj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uQ9Vt1rpYSDj",
        "outputId": "ebbcefe2-062f-4540-ae11-84d97e0f6ad9"
      },
      "outputs": [],
      "source": [
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mPAm5N3dYSDj",
      "metadata": {
        "id": "mPAm5N3dYSDj"
      },
      "source": [
        "Looking at some rows can help us spot obvious problems with data\n",
        "loading. For example, suppose we had tried to read in the data using a\n",
        "tab delimiter to separate fields on the same row, instead of a comma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Kd101-d1YSDj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Kd101-d1YSDj",
        "outputId": "c2fb3ccc-bf1f-4af1-87fa-aefeba431a32"
      },
      "outputs": [],
      "source": [
        "df_bad  = pd.read_csv(url, sep='\\t')\n",
        "df_bad.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "STAHJ2UVYSDj",
      "metadata": {
        "id": "STAHJ2UVYSDj"
      },
      "source": [
        "This ‚Äúbad‚Äù version of the `DataFrame` has only a single column (because\n",
        "it believes tabs are used to separate fields in the same row, when\n",
        "actually commas are used). The variable names are combined together into\n",
        "one long column name. By looking at the first few rows of data, we can\n",
        "spot this obvious error."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8MoJ1qnPYSDk",
      "metadata": {
        "id": "8MoJ1qnPYSDk"
      },
      "source": [
        "We should always check the shape of the data frame - the number of rows\n",
        "and columns. This, too, should be checked against our assumptions about\n",
        "the data (in this case, what we know from the NYC Data website.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vEfyeR0lYSDk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEfyeR0lYSDk",
        "outputId": "14ea21b1-29fa-473b-82ef-65e6ea26a1c4"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oza9DyTSYSDk",
      "metadata": {
        "id": "oza9DyTSYSDk"
      },
      "source": [
        "Check the names of the columns and their data types:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qI8AZfnzYSDk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI8AZfnzYSDk",
        "outputId": "78f3cb7a-bef7-4e1e-e433-adfdef464a01"
      },
      "outputs": [],
      "source": [
        "df.columns\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vqseZeIhYSDk",
      "metadata": {
        "id": "vqseZeIhYSDk"
      },
      "source": [
        "We can also get a quick summary with `info()`;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y2bCH6dQYSDk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2bCH6dQYSDk",
        "outputId": "5bed619b-945f-4355-c664-7a23bc36db1f"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jUWequ4oYSDk",
      "metadata": {
        "id": "jUWequ4oYSDk"
      },
      "source": [
        "`pandas` infers the data type of each column automatically from the\n",
        "contents of the data.\n",
        "\n",
        "If the data type of a column is not what you expect it to be, this can\n",
        "often be a signal that the data needs cleaning. For example, if you\n",
        "expect a column to be numeric and it is read in as non-numeric, this\n",
        "indicates that there are probably some samples that include a\n",
        "non-numeric value in that column. (The [NYC Data\n",
        "website](https://data.cityofnewyork.us/Transportation/Brooklyn-Bridge-Automated-Pedestrian-Counts-Demons/6fi9-q3ta)\n",
        "indicates what type of data *should* be in each column, so you should\n",
        "reference that when checking this output. )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wmeHaTdfYSDl",
      "metadata": {
        "id": "wmeHaTdfYSDl"
      },
      "source": [
        "We have a date/time column (`hour_beginning`) that was read in as a\n",
        "string. Let‚Äôs take a closer look at that. We can get one column of data\n",
        "either using a notation like a dictionary, as in\n",
        "\n",
        "``` python\n",
        "df['hour_beginning']\n",
        "```\n",
        "\n",
        "or using class attribute-like notation, as in\n",
        "\n",
        "``` python\n",
        "df.hour_beginning\n",
        "```\n",
        "\n",
        "(either one returns exactly the same thing!) (Note that if the column\n",
        "name includes spaces, you can only use the notation with the brackets,\n",
        "since it encloses the column name in quotes and can accomodate spaces.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bOZASVI3YSDp",
      "metadata": {
        "id": "bOZASVI3YSDp"
      },
      "source": [
        "`pandas` includes a `to_datetime` function to convert this string to a\n",
        "‚Äúnative‚Äù date/time format, so we can use that now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JedxrLD0YSDq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JedxrLD0YSDq",
        "outputId": "0b3a09fa-fcf1-42a9-b39c-45065059e032"
      },
      "outputs": [],
      "source": [
        "df['hour_beginning'] = pd.to_datetime(df['hour_beginning'])\n",
        "df.info()\n",
        "df['hour_beginning'].head(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KUyBoC3cYSDq",
      "metadata": {
        "id": "KUyBoC3cYSDq"
      },
      "source": [
        "You may notice that the `hour_beginning` variable includes the full date\n",
        "and time in one field. For our analysis, it would be more useful to have\n",
        "separate fields for the date, month, day of the week, and hour.\n",
        "\n",
        "We can create these additional fields by assigning the desired value to\n",
        "them directly - then, observe the effect:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "L2wjXyhSYSDq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "L2wjXyhSYSDq",
        "outputId": "986f91d6-f93f-4d49-9e3e-54b3438ec9ce"
      },
      "outputs": [],
      "source": [
        "df['hour'] = df['hour_beginning'].dt.hour\n",
        "df['month'] = df['hour_beginning'].dt.month\n",
        "df['date'] = df['hour_beginning'].dt.date\n",
        "df['day_name'] = df['hour_beginning'].dt.day_name()\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NBvg4ycJYSDq",
      "metadata": {
        "id": "NBvg4ycJYSDq"
      },
      "source": [
        "### Inspect (and possibly clean/filter) the data\n",
        "\n",
        "Now we are ready to inspect the data.\n",
        "\n",
        "-    Missing Values: We need to check if there are any missing values in the data. Sometimes, certain rows might have missing information, which can be represented as 'None', 'NaN', or even '0' or '-1'. It's essential to distinguish between actual missing values and valid values like '0' or '-1'.\n",
        "\n",
        "-    Numeric Fields: For numerical fields, we'll look at the minimum and maximum values of each field. We'll also check if the median falls within our expected range.\n",
        "\n",
        "-    Non-Numeric Fields: For non-numeric fields, we'll check the number of unique values in each field and ensure they match our expectations. We'll also examine the consistency of factor levels throughout the data.\n",
        "\n",
        "-    Variable Relationships: We'll assess if the relationships between variables align with our expectations. This can involve visual evaluation and examining summary statistics.\n",
        "\n",
        "-     Time Series Data: If the data is a time series, we'll analyze the trend of each variable over time and ensure it aligns with our expectations.\n",
        "\n",
        "These checks may require some domain knowledge. Having a good understanding of the subject matter related to the data is crucial for setting reasonable expectations about the values and relationships within the dataset.."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LgzqWpt7YSDq",
      "metadata": {
        "id": "LgzqWpt7YSDq"
      },
      "source": [
        "#### Check whether data is complete"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "na3HombSYSDq",
      "metadata": {
        "id": "na3HombSYSDq"
      },
      "source": [
        "Let us start by checking whether the data is complete. First, we‚Äôll\n",
        "check whether there are any rows in the data where some or all fields\n",
        "are missing.\n",
        "\n",
        "We can see the number of missing values in each column by summing up all\n",
        "the instances where the `isnull` function returns a True value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MXpdr_P4YSDr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXpdr_P4YSDr",
        "outputId": "6b22828e-1a5b-40ba-98c4-7440ddd6f689"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vr8ZKaBaYSDr",
      "metadata": {
        "id": "vr8ZKaBaYSDr"
      },
      "source": [
        "(Note that this only tells us about missing values that are explicitly\n",
        "denoted as such - for example, explicit `NaN` values. If a missing value\n",
        "is coded as something else - like a 0 or -1 - we wouldn‚Äôt know unless we\n",
        "noticed an unusually high frequency of 0 or -1 values.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feitQZrtYSDr",
      "metadata": {
        "id": "feitQZrtYSDr"
      },
      "source": [
        "We notice that the majority of rows are missing a value in the `events`\n",
        "field, which is used to mark dates that are holidays or other special\n",
        "events. This is reasonable, since most dates do not have any remarkable\n",
        "events.\n",
        "\n",
        "Let‚Äôs look at the rows that *do* have a value in the `events` field. To\n",
        "filter a dataframe, we‚Äôll use the `.loc[]` operator. This accepts either\n",
        "an index (for example, we can do `df.loc[0]` to see the first record in\n",
        "the dataframe), an array of indices (for example, `df.loc[[0,1,2]]`), or\n",
        "an array of boolean values the length of the entire dataframe. That‚Äôs\n",
        "what we‚Äôll use here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wn4h0k8sYSDr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "wn4h0k8sYSDr",
        "outputId": "d2e84bff-02fb-443b-ecac-7728d7b180c8"
      },
      "outputs": [],
      "source": [
        "df.loc[df['events'].notnull()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_SaiA2imYSDr",
      "metadata": {
        "id": "_SaiA2imYSDr"
      },
      "source": [
        "We also notice a small number of rows missing weather information. It‚Äôs\n",
        "not clear why these are missing. Let‚Äôs take a closer look at some of\n",
        "those rows, by *filtering* the dataframe to only rows that meet a\n",
        "specific condition - in this case, that the `temperature` field is\n",
        "missing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "opUarrBzYSDr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "id": "opUarrBzYSDr",
        "outputId": "9a424411-d63b-461a-d8eb-9fb2ae35d3d3"
      },
      "outputs": [],
      "source": [
        "df.loc[df.temperature.isnull()]   #Return values where temp is not null"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8BM4Gei8YSDs",
      "metadata": {
        "id": "8BM4Gei8YSDs"
      },
      "source": [
        "We can see that for these particular instances, all of the weather\n",
        "information is missing. There‚Äôs no obvious reason or pattern. We‚Äôll deal\n",
        "with these soon, when we try to clean/filter the data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eH6fm2m6YSDs",
      "metadata": {
        "id": "eH6fm2m6YSDs"
      },
      "source": [
        "Before we do that, though, let‚Äôs check for the *other* kind of missing\n",
        "data: rows that are missing completely, that we expect *should* be\n",
        "present.\n",
        "\n",
        "In this example, the data is a time series, and we expect that there is\n",
        "exactly one row of data for every single hour over the time period in\n",
        "which this data was collected."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PC62kqRdYSDs",
      "metadata": {
        "id": "PC62kqRdYSDs"
      },
      "source": [
        "Let‚Äôs see if the data is complete, or if there are gaps in time.\n",
        "\n",
        "First, we will use\n",
        "[`pd.date_range`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html)\n",
        "to get the list of hour intervals that we expect to find in the dataset.\n",
        "Then, we will find the difference between this list and the actual list\n",
        "of hour intervals in the dataset - these are missing intervals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UEZ0NbT4YSDs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEZ0NbT4YSDs",
        "outputId": "d8d47d3b-3c25-4de6-bffd-b74269d68b28"
      },
      "outputs": [],
      "source": [
        "# get beginning and end of date range\n",
        "min_dt = df.hour_beginning.min()\n",
        "max_dt = df.hour_beginning.max()\n",
        "print(min_dt)\n",
        "print(max_dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uQ-U26DgYSDs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ-U26DgYSDs",
        "outputId": "8e352658-34c0-4cf5-f4df-cf927336ed0b"
      },
      "outputs": [],
      "source": [
        "expected_range = pd.date_range(start = min_dt, end = max_dt, freq='H' )\n",
        "expected_range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xC0ksqaQYSDs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC0ksqaQYSDs",
        "outputId": "f36d7eb2-3929-4395-b0b1-b4fd76d88acd"
      },
      "outputs": [],
      "source": [
        "# then identify the missing hours\n",
        "missing_hours = expected_range.difference(df['hour_beginning'])\n",
        "print(missing_hours)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ExvBIbsTYSDs",
      "metadata": {
        "id": "ExvBIbsTYSDs"
      },
      "source": [
        "We had the expected number of rows (the output of `shape` matched the\n",
        "description of the data on the NYC Data website), but the data seems to\n",
        "be missing samples from August 2018 through December 2018, which is\n",
        "worth keeping in mind if we decide to use it:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Mvl3yCMFYSDu",
      "metadata": {
        "id": "Mvl3yCMFYSDu"
      },
      "source": [
        "#### Handle missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uwyaLlasYSDu",
      "metadata": {
        "id": "uwyaLlasYSDu"
      },
      "source": [
        "Now that we have evaluated the ‚Äúcompleteness‚Äù of our data, we have to\n",
        "decide what to do about missing values.\n",
        "\n",
        "Some machine learning models cannot tolerate data with missing values.\n",
        "Depending on what *type* of data is missing and *why* it is missing, we\n",
        "can\n",
        "\n",
        "-   drop rows with missing values from the dataset\n",
        "-   fill in (‚Äúimpute‚Äù) the missing values with some value: a 0, the mode\n",
        "    of that column, the median of that column, or forward/back fill data\n",
        "    from the nearest row that is not missing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mSCqZu_9YSDu",
      "metadata": {
        "id": "mSCqZu_9YSDu"
      },
      "source": [
        "Given the temporal nature of the data and the relatively slow changes in the weather variable over time, let's consider using the *forward/back fill* method to handle missing values. This approach is logical since consecutive observations in time are likely to have similar weather conditions.\n",
        "\n",
        "To implement this method, we'll need to arrange the data in chronological order. It's important to note that the original dataset was not sorted by time, so we'll need to sort it first before applying the forward/back fill method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Grjuqk45YSDu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Grjuqk45YSDu",
        "outputId": "1cfb0390-1daf-45ce-df8a-47faff503709"
      },
      "outputs": [],
      "source": [
        "df = df.sort_values(by='hour_beginning') #Arranging data in chronological order first and then proceeding to forward/back fill\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ApXDn8wYSDu",
      "metadata": {
        "id": "0ApXDn8wYSDu"
      },
      "source": [
        "We can also ‚Äúreset‚Äù the index now, so that if we ask for `df.loc[0]`\n",
        "we‚Äôll get the first row in time, and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zUnwrZY4YSDu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zUnwrZY4YSDu",
        "outputId": "cda0e489-cb74-4b1f-e2c6-8bbd4021e71b"
      },
      "outputs": [],
      "source": [
        "df.reset_index(drop=True, inplace=True)  #drop=True discards the current index, inplace=True applies changes to the df\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E8x8ekk2YSDu",
      "metadata": {
        "id": "E8x8ekk2YSDu"
      },
      "source": [
        "Now we can fill in missing data using the `fillna` function\n",
        "([reference](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)).\n",
        "We will fill the missing weather data using the ‚Äúforward fill‚Äù method,\n",
        "which caries the last valid observation forward to fill in NAs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "-n45rCgIYSDu",
      "metadata": {
        "id": "-n45rCgIYSDu"
      },
      "outputs": [],
      "source": [
        "df['temperature'] = df['temperature'].fillna(method=\"ffill\")\n",
        "df['precipitation'] = df['precipitation'].fillna(method=\"ffill\")\n",
        "df['weather_summary'] = df['weather_summary'].fillna(method=\"ffill\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g7C8keCIYSDv",
      "metadata": {
        "id": "g7C8keCIYSDv"
      },
      "source": [
        "Having imputed missing vaules in the weather-related columns, we can\n",
        "count the NAs again and find that there are only missing values in the\n",
        "`events` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XPLnaFhIYSDv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPLnaFhIYSDv",
        "outputId": "916ad4a6-57aa-469a-a318-58d4a8f253bd"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2b_BdRsYSDv",
      "metadata": {
        "id": "a2b_BdRsYSDv"
      },
      "source": [
        "#### Validating expectations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oYcQoR_AYSDv",
      "metadata": {
        "id": "oYcQoR_AYSDv"
      },
      "source": [
        "\n",
        "Now that we have assessed the data's completeness, let's turn our attention to evaluating the consistency of the data values with our expectations.\n",
        "\n",
        "To begin, we'll examine summary statistics. The \"five-number summary\" ‚Äì including extremes (minimum and maximum values), median, and quartiles ‚Äì provides valuable insights into numeric fields within the data. This summary allows us to assess whether the values fall within reasonable ranges. We can leverage the describe function in pandas to compute this summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o9H01NV7YSDv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "o9H01NV7YSDv",
        "outputId": "6711775a-8f97-415e-8fda-9ed36ecc67cd"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KL8Aw4tCYSDv",
      "metadata": {
        "id": "KL8Aw4tCYSDv"
      },
      "source": [
        "We can only compute those summary statistics for numerical variables.\n",
        "For categorical variables, we can use `value_counts()` to get frequency\n",
        "of each value.\n",
        "\n",
        "For example, let‚Äôs see how often each `weather` condition occurs, and\n",
        "whether it is reasonable for NYC:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZVxWZwnGYSDv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVxWZwnGYSDv",
        "outputId": "d9a674f4-0d9e-4639-a4a6-1e9541fd6911"
      },
      "outputs": [],
      "source": [
        "df.weather_summary.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EfUYtnghYSDw",
      "metadata": {
        "id": "EfUYtnghYSDw"
      },
      "source": [
        "It‚Äôs also useful to verify expected relationships.\n",
        "\n",
        "For example, we expect to see precipitation when the weather is rainy.\n",
        "We can use `groupby` in `pandas` to capture the effect between a\n",
        "categorical variable (`weather_summary`) and a numerical one,\n",
        "`precipitation`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LiQJ38dWYSDw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "LiQJ38dWYSDw",
        "outputId": "f112eba1-3042-4492-cb75-a56605cff827"
      },
      "outputs": [],
      "source": [
        "df.groupby('weather_summary')['precipitation'].describe()   #It computes summary statistics for the 'precipitation' values within each group."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JBOL-P8HYSDw",
      "metadata": {
        "id": "JBOL-P8HYSDw"
      },
      "source": [
        "Make special note of the `count` column, which shows us the prevalence\n",
        "of different weather conditions in this dataset. There are some weather\n",
        "conditions for which we have very few examples."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-rkJOEp5YSDw",
      "metadata": {
        "id": "-rkJOEp5YSDw"
      },
      "source": [
        "Similarly, we can validate our expectation of hotter weather in the\n",
        "summer months:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OkcDy4_8YSDw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "OkcDy4_8YSDw",
        "outputId": "5d562ef0-719a-4ba5-a46f-3d771bc8bfc1"
      },
      "outputs": [],
      "source": [
        "df.groupby('month')['temperature'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "O8goe6oYYSDw",
      "metadata": {
        "id": "O8goe6oYYSDw"
      },
      "source": [
        "as well as during the middle of the day:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eO6gUoa4YSDw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "eO6gUoa4YSDw",
        "outputId": "69594f5d-d995-4779-9a44-2f3827df1cb3"
      },
      "outputs": [],
      "source": [
        "df.groupby('hour')['temperature'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D90NXNDHqxW0",
      "metadata": {
        "id": "D90NXNDHqxW0"
      },
      "source": [
        "##Data Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PTC6GrdFtrPW",
      "metadata": {
        "id": "PTC6GrdFtrPW"
      },
      "source": [
        "Data visualization is a powerful tool used to explore, analyze, and communicate insights from data. It involves representing data visually through charts, graphs, and plots to uncover patterns, trends, and relationships that may not be immediately apparent from raw data alone"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I4VFifEkYSDx",
      "metadata": {
        "id": "I4VFifEkYSDx"
      },
      "source": [
        "#### 1. Pairplot"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bZ4Mj4xYSDx",
      "metadata": {
        "id": "1bZ4Mj4xYSDx"
      },
      "source": [
        "For tabular data with multiple numeric features, it is often useful to\n",
        "create a *pairplot*. A pairplot shows pairwise relationships between all\n",
        "numerical variables. It is a useful way to identify variables that have\n",
        "a relationship."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lKOqu1sJYSDx",
      "metadata": {
        "id": "lKOqu1sJYSDx"
      },
      "source": [
        "We can create a pairplot with Seaborn library like so :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rOoCDqZIFRRU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rOoCDqZIFRRU",
        "outputId": "f9f929d8-d908-4c7b-ab97-66e2fb2c48be"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df,\n",
        "             vars=['Pedestrians', 'temperature', 'precipitation', 'hour', 'month'],\n",
        "             plot_kws={'alpha':0.5, 'size': 0.1})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9UWfsRBHYSDx",
      "metadata": {
        "id": "9UWfsRBHYSDx"
      },
      "source": [
        "Here, each pane shows one numerical variable on the x-axis and another\n",
        "numerical variable on the y-axis, so that we can see if a relationship\n",
        "exists between them. The panes along the diagonal shows the empirical\n",
        "distribution of values for each feature in this data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FZKKI913YSDx",
      "metadata": {
        "id": "FZKKI913YSDx"
      },
      "source": [
        "But, it is difficult to see anything useful because there is so much\n",
        "going on in this plot. We can improve things somewhat by:\n",
        "\n",
        "-   specifying only the variables we want to include, and exluding\n",
        "    variables that don‚Äôt contain useful information, such as `lat` and\n",
        "    `long`, and\n",
        "-   making the points on the plot smaller and partially transparent, to\n",
        "    help with the overplotting.\n",
        "\n",
        "We‚Äôll also change the histograms on the diagonal, which show the\n",
        "frequency of values for each variable, into a density plot which shows\n",
        "the same information in a more useful format."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_jjqk6jGYSDx",
      "metadata": {
        "id": "_jjqk6jGYSDx"
      },
      "source": [
        "This plot validates the relationship between `temperature` and `hour`,\n",
        "and between `temperature` and `month`. However, we can also use this\n",
        "plot to identify useful features - features that appear to be related to\n",
        "the `target` variable."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p4bC7bhnw3m6",
      "metadata": {
        "id": "p4bC7bhnw3m6"
      },
      "source": [
        "#### 2. Histogram : Show the distribution of a numerical variable\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8PYvEcfRvHvT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "8PYvEcfRvHvT",
        "outputId": "a57fffbe-0d1e-4cc3-ff0f-b61fdb169ad3"
      },
      "outputs": [],
      "source": [
        "# Plotting a histogram of pedestrian counts\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=df, x='Pedestrians')\n",
        "plt.title('Histogram of Pedestrians on Brooklyn Bridge')\n",
        "plt.xlabel('Pedestrian Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A8smXIFO9M4e",
      "metadata": {
        "id": "A8smXIFO9M4e"
      },
      "source": [
        "#### 3. Scatterplot: Graphical representation used to display the relationship between two continuous variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7XB0p0_0xHSg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "7XB0p0_0xHSg",
        "outputId": "260b70bf-3892-4b85-e315-7d258d1db384"
      },
      "outputs": [],
      "source": [
        "# Generating a scatterplot of temperature against pedestrian counts\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(df['temperature'], df['Pedestrians'], color='green', alpha=0.5)  #alpha controls the transparency of markers\n",
        "plt.title('Scatterplot of Temperature vs Pedestrian Counts')\n",
        "plt.xlabel('Temperature')\n",
        "plt.ylabel('Pedestrian Count')\n",
        "plt.grid(True) #Adds a grid to the data\n",
        "plt.tight_layout()  #Prevents overlapping elements\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mLoRiQMU4pC8",
      "metadata": {
        "id": "mLoRiQMU4pC8"
      },
      "source": [
        "#### 4. Bar Graph: Show a numerical comparison across different categories\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xSUuygTPxSuh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "xSUuygTPxSuh",
        "outputId": "dd0fd204-5d21-4fd5-b8a1-7a51e1257e70"
      },
      "outputs": [],
      "source": [
        "# Aggregating pedestrian counts by hour and plotting a bar graph\n",
        "hourly_counts = df.groupby(df['hour'])['Pedestrians'].sum()\n",
        "plt.figure(figsize=(12, 6))\n",
        "hourly_counts.plot(kind='bar', color='orange')\n",
        "plt.title('Total Pedestrian Counts by Hour')\n",
        "plt.xlabel('Hour of the Day')\n",
        "plt.ylabel('Pedestrian Count')\n",
        "plt.grid(axis='y')  #grid created alone y axis\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afL2Arwh7CY8",
      "metadata": {
        "id": "afL2Arwh7CY8"
      },
      "source": [
        "#### 5.Line Plot : Show the trend of a numerical variable over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vTD1X4zR05Cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "vTD1X4zR05Cd",
        "outputId": "1dc41bf9-56b0-4e2b-cd71-4491c1b34e63"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plotting a line plot of pedestrian counts over time\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df['hour_beginning'], df['Pedestrians'], color='blue')\n",
        "plt.title('Pedestrian Counts Over Time')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Pedestrian Count')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DSDNwRtO5aiJ",
      "metadata": {
        "id": "DSDNwRtO5aiJ"
      },
      "source": [
        "#### 6. Box Plot : Show quartiles (and outliers) for one or more numerical variables\n",
        "\n",
        "We can use boxplots to quickly summarize distributions.\n",
        "\n",
        "Five-number summary:\n",
        "\n",
        "min = minimum value\n",
        "25% = first quartile (Q1) = median of the lower half of the data\n",
        "50% = second quartile (Q2) = median of the data\n",
        "75% = third quartile (Q3) = median of the upper half of the data\n",
        "max = maximum value\n",
        "(It's more useful than mean and standard deviation for describing skewed distributions.)\n",
        "\n",
        "Interquartile Range (IQR) = Q3 - Q1\n",
        "\n",
        "Outliers:\n",
        "\n",
        "below Q1 - 1.5 * IQR\n",
        "above Q3 + 1.5 * IQR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l6__AI4n1G-1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "id": "l6__AI4n1G-1",
        "outputId": "f5052f42-d277-4c33-85b3-306777cb1d4d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plotting a box plot of pedestrian counts by weather summary\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df, x='weather_summary', y='Pedestrians')\n",
        "plt.title('Pedestrian Counts by Weather Summary')\n",
        "plt.xlabel('Weather Summary')\n",
        "plt.ylabel('Pedestrian Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WYu4-u965pIV",
      "metadata": {
        "id": "WYu4-u965pIV"
      },
      "source": [
        "#### 7. Heatmap : When you have too many variables, a pairplot or scatter matrix can become impossible to read. We can still gauge linear correlation using a heatmap of the correlation matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fTfDHej1w75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "3fTfDHej1w75",
        "outputId": "13770a70-31af-4a47-951f-809d9e6e2e53"
      },
      "outputs": [],
      "source": [
        "# Creating a correlation matrix\n",
        "correlation_matrix = df[['Pedestrians', 'temperature', 'precipitation']].corr()\n",
        "\n",
        "# Plotting the correlation matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix of Pedestrians, Temperature, and Precipitation')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_cgnn9co2P_f",
      "metadata": {
        "id": "_cgnn9co2P_f"
      },
      "source": [
        "A correlation coefficient of -0.10 suggests that there is a very slight tendency for pedestrian counts to decrease slightly when there is more precipitation. However, the correlation is weak, meaning that precipitation alone may not be a strong predictor of pedestrian counts, and other factors likely play a more significant role.\n",
        "\n",
        "A correlation coefficient of 0.37 suggests that there is a moderate tendency for pedestrian counts to increase as the temperature increases. However, it's essential to consider other factors that may also influence pedestrian behavior, as the correlation does not imply causation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JvQ5AgQqYSDz",
      "metadata": {
        "id": "JvQ5AgQqYSDz"
      },
      "source": [
        "Now armed with information about these relationships, we can identify\n",
        "good candidate features for a machine learning model."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
